{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Nama :** Rully Lukas T      **                                                                                               \n",
        "NIM : **1103200181    **                                                                                                                                             \n",
        "Model : **SplitOVer**"
      ],
      "metadata": {
        "id": "7Vm7An7LLGht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ivyQdJ5h8cd",
        "outputId": "bfdd8fc6-3717-4233-e54c-1fa3ed2b5ee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\"
      ],
      "metadata": {
        "id": "M-UT0i0XK7vY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kd797Vxph1-l"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from shutil import copyfile\n",
        "import os.path\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array,load_img\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from numpy import load\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "imagegen = ImageDataGenerator()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patho = {'Bayam': 0, 'Kangkung_Air': 1, 'Kangkung_Darat': 2, 'Kelor': 3, 'Pakis': 4}"
      ],
      "metadata": {
        "id": "keelaq3Gi9Z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train data from drive\n",
        "train_generator = imagegen.flow_from_directory(\"/content/drive/MyDrive/Statistik\",\n",
        "                                               class_mode=\"categorical\",\n",
        "                                               shuffle=False,\n",
        "                                               batch_size=16,  # Use a smaller batch size\n",
        "                                               target_size=(512, 512),\n",
        "                                               seed=42)\n",
        "\n",
        "x_list = []\n",
        "y_list = []"
      ],
      "metadata": {
        "id": "xjRXYHQmiNoy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b302bae4-dc4c-4339-fc62-c8eaf15283da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1575 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and process images in batches\n",
        "for i in range(len(train_generator)):\n",
        "    x_batch, y_batch = train_generator.next()\n",
        "    x_list.append(x_batch)\n",
        "    y_list.append(y_batch)\n",
        "\n",
        "    # Flatten labels and check unique classes\n",
        "    y_labels = np.argmax(y_batch, axis=1)\n",
        "    unique_classes = np.unique(y_labels)\n",
        "\n",
        "    # Check if we have at least two classes and enough samples for ADASYN\n",
        "    if len(unique_classes) > 1:\n",
        "        x_concat = np.concatenate(x_list)\n",
        "        y_concat = np.concatenate(y_list)\n",
        "\n",
        "        X_batch = x_concat.reshape(x_concat.shape[0], -1)\n",
        "        y_labels_concat = np.argmax(y_concat, axis=1)\n",
        "\n",
        "        # Set the n_neighbors parameter to be less than or equal to the number of samples in the smallest class\n",
        "        min_samples = np.min(np.bincount(y_labels_concat))\n",
        "        n_neighbors = max(1, min(5, min_samples - 1))\n",
        "\n",
        "        if min_samples > 1:  # Ensure we have more than one sample for the smallest class\n",
        "            adasyn = ADASYN(sampling_strategy='minority', n_neighbors=n_neighbors, random_state=42)\n",
        "            X_adasyn, y_adasyn = adasyn.fit_resample(X_batch, y_labels_concat)\n",
        "            X_adasyn = X_adasyn.reshape(-1, 512, 512, 3)\n",
        "\n",
        "            # Save ADASYN generated images\n",
        "            train_sep_dir = '/content/drive/MyDrive/Bukti_kas'\n",
        "\n",
        "            # Create a \"testfolder\" if it does not exist on the drive\n",
        "            if not os.path.exists(train_sep_dir):\n",
        "                os.mkdir(train_sep_dir)\n",
        "\n",
        "            # This function returns the label name\n",
        "            def get_key(val):\n",
        "                for key, value in patho.items():\n",
        "                    if val == value:\n",
        "                        return key\n",
        "\n",
        "            for j in range(len(X_adasyn)):\n",
        "                label = get_key(y_adasyn[j])\n",
        "                label_dir = os.path.join(train_sep_dir, str(label))\n",
        "\n",
        "                if not os.path.exists(label_dir):\n",
        "                    os.mkdir(label_dir)\n",
        "\n",
        "                pil_img = array_to_img(X_adasyn[j] * 255)\n",
        "                pil_img.save(os.path.join(label_dir, 'adasyn_' + str(i) + '_' + str(j) + '.jpg'))\n",
        "\n",
        "            # Reset lists after processing\n",
        "            x_list = []\n",
        "            y_list = []\n",
        "\n",
        "            print(f\"Processed batch {i+1}/{len(train_generator)}\")\n",
        "\n",
        "# If there's any leftover data that wasn't processed, process it now\n",
        "if len(x_list) > 0:\n",
        "    x_concat = np.concatenate(x_list)\n",
        "    y_concat = np.concatenate(y_list)\n",
        "\n",
        "    X_batch = x_concat.reshape(x_concat.shape[0], -1)\n",
        "    y_labels_concat = np.argmax(y_concat, axis=1)\n",
        "\n",
        "    min_samples = np.min(np.bincount(y_labels_concat))\n",
        "    n_neighbors = max(1, min(5, min_samples - 1))\n",
        "\n",
        "    if min_samples > 1:\n",
        "        adasyn = ADASYN(sampling_strategy='minority', n_neighbors=n_neighbors, random_state=42)\n",
        "        X_adasyn, y_adasyn = adasyn.fit_resample(X_batch, y_labels_concat)\n",
        "        X_adasyn = X_adasyn.reshape(-1, 512, 512, 3)\n",
        "\n",
        "        for j in range(len(X_adasyn)):\n",
        "            label = get_key(y_adasyn[j])\n",
        "            label_dir = os.path.join(train_sep_dir, str(label))\n",
        "\n",
        "            if not os.path.exists(label_dir):\n",
        "                os.mkdir(label_dir)\n",
        "\n",
        "            pil_img = array_to_img(X_adasyn[j] * 255)\n",
        "            pil_img.save(os.path.join(label_dir, 'adasyn_' + 'final_' + str(j) + '.jpg'))\n",
        "\n",
        "print(\"Processing complete.\")"
      ],
      "metadata": {
        "id": "VlImiZw7y9X0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "1a1e0832-7f59-4e3d-83c9-11a11de04083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-159de2031703>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load and process images in batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mx_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mfilepaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             img = image_utils.load_img(\n\u001b[0m\u001b[1;32m    371\u001b[0m                 \u001b[0mfilepaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth_height_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrop_box\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth_height_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2154\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2156\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m             \u001b[0mbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and process images in batches\n",
        "for i in range(len(train_generator)):\n",
        "    x_batch, y_batch = train_generator.next()\n",
        "    x_list.append(x_batch)\n",
        "    y_list.append(y_batch)\n",
        "\n",
        "x_concat = np.concatenate(x_list)\n",
        "y_concat = np.concatenate(y_list)\n",
        "\n",
        "# Flatten labels\n",
        "y_labels_concat = np.argmax(y_concat, axis=1)\n",
        "\n",
        "# Reshape data for undersampling\n",
        "X_batch = x_concat.reshape(x_concat.shape[0], -1)\n",
        "\n",
        "# Apply RandomUnderSampler to balance all classes\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_rus, y_rus = rus.fit_resample(X_batch, y_labels_concat)\n",
        "\n",
        "# Reshape back to image dimensions\n",
        "X_rus = X_rus.reshape(-1, 512, 512, 3)\n",
        "\n",
        "# Save RandomUnderSampler generated images\n",
        "train_sep_dir = '/content/drive/MyDrive/Scracth'\n",
        "\n",
        "# Create a \"testfolder\" if it does not exist on the drive\n",
        "if not os.path.exists(train_sep_dir):\n",
        "    os.mkdir(train_sep_dir)\n",
        "\n",
        "# This function returns the label name\n",
        "def get_key(val):\n",
        "    for key, value in patho.items():\n",
        "        if val == value:\n",
        "            return key\n",
        "\n",
        "for j in range(len(X_rus)):\n",
        "    label = get_key(y_rus[j])\n",
        "    label_dir = os.path.join(train_sep_dir, str(label))\n",
        "\n",
        "    if not os.path.exists(label_dir):\n",
        "        os.mkdir(label_dir)\n",
        "\n",
        "    pil_img = array_to_img(X_rus[j] * 255)\n",
        "    pil_img.save(os.path.join(label_dir, 'rus_' + str(j) + '.jpg'))\n",
        "\n",
        "print(\"Processing complete.\")"
      ],
      "metadata": {
        "id": "gf1Kd7fn1L89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "/content/drive/MyDrive/Bukti_kas"
      ],
      "metadata": {
        "id": "NHvObzgdz6WX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define the paths\n",
        "data_dir = '/content/drive/MyDrive/Statistik/Over'  # Replace with the path to your dataset folder\n",
        "train_dir = '/content/drive/MyDrive/Statistik/SplitOver/train'   # Replace with the path to save training data\n",
        "test_dir = '/content/drive/MyDrive/Statistik/SplitOver/test'     # Replace with the path to save testing data\n",
        "\n",
        "# Set parameters\n",
        "img_height = 224  # Set to the height of your images\n",
        "img_width = 224   # Set to the width of your images\n",
        "batch_size = 32   # You can adjust the batch size according to your requirements\n",
        "\n",
        "# Define ImageDataGenerator for training and testing\n",
        "train_datagen = ImageDataGenerator(validation_split=0.2)  # 20% for validation\n",
        "\n",
        "# Load the training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'  # Set as training data\n",
        ")\n",
        "\n",
        "# Load the validation data\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'  # Set as validation data\n",
        ")\n",
        "\n",
        "# Optional: Save the split datasets if required\n",
        "# Here we show how to save them, but it's not necessary if you directly load them as above\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "def copy_files(generator, dest_dir):\n",
        "    class_indices = generator.class_indices\n",
        "    for class_name, class_index in class_indices.items():\n",
        "        os.makedirs(os.path.join(dest_dir, class_name), exist_ok=True)\n",
        "\n",
        "    for i in range(len(generator)):\n",
        "        x, y = next(generator)\n",
        "        for j in range(len(x)):\n",
        "            img = tf.keras.preprocessing.image.array_to_img(x[j])\n",
        "            label = list(class_indices.keys())[list(y[j]).index(1)]\n",
        "            img.save(os.path.join(dest_dir, label, f'{i}_{j}.jpg'))\n",
        "\n",
        "copy_files(train_generator, train_dir)\n",
        "copy_files(validation_generator, test_dir)"
      ],
      "metadata": {
        "id": "G0frsbN67b9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define the paths\n",
        "data_dir = '/content/drive/MyDrive/Statistik/Over'  # Replace with the path to your dataset folder\n",
        "train_dir = '/content/drive/MyDrive/Statistik/SplitOver/train'   # Replace with the path to save training data\n",
        "test_dir = '//content/drive/MyDrive/Statistik/SplitOver/test'     # Replace with the path to save testing data\n",
        "\n",
        "# Set parameters\n",
        "img_height = 224  # Set to the height of your images\n",
        "img_width = 224   # Set to the width of your images\n",
        "batch_size = 32   # You can adjust the batch size according to your requirements\n",
        "\n",
        "# Define ImageDataGenerator for training and testing\n",
        "train_datagen = ImageDataGenerator(validation_split=0.2)  # 20% for validation\n",
        "\n",
        "# Load the training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'  # Set as training data\n",
        ")\n",
        "\n",
        "# Load the validation data\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'  # Set as validation data\n",
        ")\n",
        "\n",
        "# Optional: Save the split datasets if required\n",
        "# Here we show how to save them, but it's not necessary if you directly load them as above\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "def copy_files(generator, dest_dir):\n",
        "    class_indices = generator.class_indices\n",
        "    for class_name, class_index in class_indices.items():\n",
        "        os.makedirs(os.path.join(dest_dir, class_name), exist_ok=True)\n",
        "\n",
        "    for i in range(len(generator)):\n",
        "        x, y = next(generator)\n",
        "        for j in range(len(x)):\n",
        "            img = tf.keras.preprocessing.image.array_to_img(x[j])\n",
        "            label = list(class_indices.keys())[list(y[j]).index(1)]\n",
        "            img.save(os.path.join(dest_dir, label, f'{i}_{j}.jpg'))\n",
        "\n",
        "copy_files(train_generator, train_dir)\n",
        "copy_files(validation_generator, test_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHfJsMq1Au7Y",
        "outputId": "584a9b3c-6545-48d7-8efc-764d609daec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 580 images belonging to 5 classes.\n",
            "Found 145 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V1Hk2d9VFd7P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}